{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a2190-5707-4c53-8b1d-412b6c9c6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate trained models on the official CUB test set\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import joblib\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "sys.path.append('/home/mattyshen/interpretableDistillation')\n",
    "from interpretDistill import fourierDistill\n",
    "sys.path.append('/home/mattyshen/iCBM')\n",
    "\n",
    "from CUB.dataset import load_data\n",
    "from CUB.config import BASE_DIR, N_CLASSES, N_ATTRIBUTES, DEVICE, get_device, set_device\n",
    "from analysis import AverageMeter, multiclass_metric, accuracy, binary_accuracy\n",
    "\n",
    "from imodels import FIGSClassifierCV\n",
    "\n",
    "\n",
    "class ARGS:\n",
    "    def __init__(self, a_dict):\n",
    "        for k in a_dict.keys():\n",
    "            exec(f'self.{k} = a_dict[\"{k}\"]')\n",
    "            \n",
    "parser_args = ['log_dir', \n",
    "               'model_dirs', \n",
    "               'model_dirs2', \n",
    "               'eval_data', \n",
    "               'use_attr', \n",
    "               'no_img', \n",
    "               'bottleneck', \n",
    "               'image_dir', \n",
    "               'n_class_attr', \n",
    "               'data_dir', \n",
    "               'n_attributes', \n",
    "               'attribute_group',\n",
    "               'feature_group_results', \n",
    "               'use_relu', \n",
    "               'use_sigmoid', \n",
    "               'use_gbsm', \n",
    "               'expand_gbsm_dim', \n",
    "               'gpu']\n",
    "parser_sigmoid = ['/home/mattyshen/iCBM/CUB/eval/JointSigmoidModels/outputs', \n",
    "               ['/home/mattyshen/iCBM/CUB/best_models/Joint0.01SigmoidModel__Seed1/outputs/best_model_1.pth', '/home/mattyshen/iCBM/CUB/best_models/Joint0.01SigmoidModel__Seed2/outputs/best_model_2.pth', '/home/mattyshen/iCBM/CUB/best_models/Joint0.01SigmoidModel__Seed3/outputs/best_model_3.pth'],\n",
    "               None,\n",
    "               'test',\n",
    "               True,\n",
    "               False,\n",
    "               False,\n",
    "               'images',\n",
    "               2,\n",
    "               'CUB_processed/class_attr_data_10',\n",
    "               112,\n",
    "               None,\n",
    "               False,\n",
    "               False,\n",
    "               True,\n",
    "               False,\n",
    "               False,\n",
    "               2]\n",
    "parser_gbsm = ['/home/mattyshen/iCBM/CUB/eval/JointGBSMModels/outputs', \n",
    "               ['/home/mattyshen/iCBM/CUB/best_models/Joint0.01GBSMModel__Seed1/outputs/best_model_1.pth', '/home/mattyshen/iCBM/CUB/best_models/Joint0.01GBSMModel__Seed2/outputs/best_model_2.pth', '/home/mattyshen/iCBM/CUB/best_models/Joint0.01GBSMModel__Seed3/outputs/best_model_3.pth'],\n",
    "               None,\n",
    "               'test',\n",
    "               True,\n",
    "               False,\n",
    "               False,\n",
    "               'images',\n",
    "               2,\n",
    "               'CUB_processed/class_attr_data_10',\n",
    "               112,\n",
    "               None,\n",
    "               False,\n",
    "               False,\n",
    "               True,\n",
    "               True,\n",
    "               False,\n",
    "               2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af1cc4-e7c5-43cd-a49d-559f0b01ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = dict(zip(parser_args, parser_sigmoid))\n",
    "torch.backends.cudnn.benchmark=True\n",
    "args = ARGS(args_dict)\n",
    "\n",
    "set_device(args.gpu)\n",
    "\n",
    "args.three_class = (args.n_class_attr == 3)\n",
    "args.batch_size = 16\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d94884-4234-453d-b813-0cee39a2af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FT_data(args, data='trainval', p_thresh=0.5):\n",
    "    #TODO: loop over all models\n",
    "    model = torch.load(args.model_dirs[0])\n",
    "    model = model.to(get_device())\n",
    "    model.eval()\n",
    "    if data == 'test':\n",
    "        test_dir = data_dir = os.path.join(BASE_DIR, args.data_dir, 'test.pkl')\n",
    "        loader = load_data([test_dir], args.use_attr, args.no_img, 32, image_dir=args.image_dir,\n",
    "                           n_class_attr=args.n_class_attr)\n",
    "    else:\n",
    "        train_dir = data_dir = os.path.join(BASE_DIR, args.data_dir, 'train.pkl')\n",
    "        val_dir = data_dir = os.path.join(BASE_DIR, args.data_dir, 'val.pkl')\n",
    "        loader = load_data([train_dir, val_dir], args.use_attr, args.no_img, 32, image_dir=args.image_dir,\n",
    "                           n_class_attr=args.n_class_attr)\n",
    "    train_val_attrs = []\n",
    "    train_val_labels = []\n",
    "    train_val_labels_hat = []\n",
    "    for data_idx, data in enumerate(loader):\n",
    "        inputs, labels, attr_labels = data\n",
    "        attr_labels = torch.stack(attr_labels).t()  # N x 312\n",
    "\n",
    "        inputs_var = torch.autograd.Variable(inputs).to(get_device())\n",
    "        labels_var = torch.autograd.Variable(labels).to(get_device())\n",
    "        #labels = labels.to(get_device()) if torch.cuda.is_available() else labels\n",
    "\n",
    "        outputs = model(inputs_var)\n",
    "        class_outputs = outputs[0]\n",
    "        \n",
    "        attr_outputs = [torch.nn.Sigmoid()(o) for o in outputs[1:]]\n",
    "        attr_outputs_sigmoid = attr_outputs\n",
    "        \n",
    "        train_val_attrs.append(torch.stack(attr_outputs).squeeze(2).detach().cpu().numpy().T)\n",
    "        train_val_labels_hat.append(np.argmax(class_outputs.detach().cpu().numpy(), axis = 1))\n",
    "        train_val_labels.append(labels)\n",
    "        \n",
    "    # X_train = pd.DataFrame(np.concatenate(train_val_attrs, axis=0) > p_thresh, columns = [f'c{i}' for i in range(1, 113)]).astype(np.int64)\n",
    "    X_train = pd.DataFrame(np.concatenate(train_val_attrs, axis=0), columns = [f'c{i}' for i in range(1, 113)])\n",
    "    y_train = pd.Series(np.concatenate([l.numpy().reshape(-1, ) for l in train_val_labels]))\n",
    "    y_train_hat = pd.Series(np.concatenate(train_val_labels_hat))\n",
    "    \n",
    "    return X_train, y_train, y_train_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7eb8f8-770b-4ee1-9cfc-91b15caf7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, y_train_hat = get_FT_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f1381-e786-4eec-b273-d032f07dff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae01b58-46d1-4389-84bb-1f786840b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    if np.any(np.where(y_train_hat == i, 1, 0) == np.nan):\n",
    "        print(i)\n",
    "    #print(np.any(np.where(y_train_hat == i, 1, 0) == None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2856e98-8859-4118-8e41-a9cb162c57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(figs_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53904fb1-6b7c-4ca0-8a3b-14ddea0dd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_models2 = []\n",
    "for i in range(145, 200):\n",
    "    if i%25 == 0:\n",
    "        print(f'training class {i}')\n",
    "    figs_i = FIGSClassifierCV(n_rules_list = [20, 20], n_trees_list = [5, 10])\n",
    "    figs_i.fit(X_train, np.where(y_train_hat == i, 1, 0))\n",
    "    figs_models.append(figs_i)\n",
    "    #np.where(y_train_hat == 46, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3e52d-815a-4127-98f2-ba02decc8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.where(y_train_hat == 147, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a9c3f-9151-4737-9d93-320b370a89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_i = FIGSClassifierCV(n_rules_list = [20, 20], n_trees_list = [5, 10])\n",
    "figs_i.fit(X_train, np.where(y_train_hat == i, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e01b7-900c-431f-bad2-ddeb228c3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_models = []\n",
    "for i in range(0, 200):\n",
    "    if i%25 == 0:\n",
    "        print(f'training class {i}')\n",
    "    figs_i = FIGSClassifierCV(n_rules_list = [20, 20], n_trees_list = [5, 10])\n",
    "    if np.sum(np.where(y_train_hat == i, 1, 0)) > 0:\n",
    "        figs_i.fit(X_train, np.where(y_train_hat == i, 1, 0))\n",
    "    figs_models.append(figs_i)\n",
    "    #np.where(y_train_hat == 46, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073bb6f-4215-47b1-857b-c71726ef73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(figs_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58d6a0-267b-4722-a196-a14d579f51c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in figs_models:\n",
    "    if hasattr(i, 'figs'):\n",
    "        print(i.predict_proba(X_train)[:, 0].shape)\n",
    "        predictions.append(i.predict_proba(X_train)[:, 0])\n",
    "    else:\n",
    "        print(np.zeros((X_train.shape[0], )).shape)\n",
    "        predictions.append(np.zeros((X_train.shape[0], )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2f172-4480-4f14-976c-2e13de9b4ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.vstack((predictions)).T, axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a024b4-7e3c-4401-b3b4-7afe3b52d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.vstack((predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5a93b-087f-4a74-8d7d-31a53cf0befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.argmax(np.vstack((predictions)).T, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f768e334-eaff-442d-a402-b1a7a43ac19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.argmax(np.vstack((predictions)).T, axis = 1) == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde43be7-7811-4192-9abb-20e2630d9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95841dd-efeb-4e67-be21-c125a1478d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_models[i].predict_proba(X_train).shape, figs_models[i].predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c87bdd-c483-4fda-aa5e-f4371332f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0fe31-92ec-42c6-b919-df91c39a1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_train_hat == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b960098-4ca1-42ed-9932-2a5c7fc06a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = FIGSClassifierCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07ca97-2107-4a33-9b9c-79aac3bd8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3df793-05b2-439c-8e7a-583a452c7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_distill = FIGSClassifierCV()\n",
    "figs_distill.fit(X_train, y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107e760-d29d-4ef6-a693-592344a5d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(figs_distill.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca046415-082b-4d24-b547-b178f83a4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(figs.predict(X_train) == y_train), np.mean(figs_distill.predict(X_train) == y_train), np.mean(figs_distill.predict(X_train) == y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f411d-4461-4612-a4f3-800fd465196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd = fourierDistill.FTDistillClassifierCV(pre_interaction='l0l2', \n",
    "                             pre_max_features=75,\n",
    "                             post_interaction='l0l2', \n",
    "                             post_max_features=50,\n",
    "                             size_interactions=3,  \n",
    "                             cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90498967-ddc5-40bb-b91b-42ff08403e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9832d2f-3f8d-4d81-bff5-c4e0d26e9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = get_FT_data(args, data='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748fad9f-1b59-493f-9e3a-6421e6986bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.Series(np.concatenate([l.numpy().reshape(-1, ) for l in y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c73fc-030d-474a-88f4-1af3fc8a059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(np.sum(ftd.post_sparsity_model.coef_ != 0, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea4559-3221-4f7c-ae94-1cd515974054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7072c5-5a84-4573-8d21-81a549e64b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ftd.predict(X_train) == y_train), np.mean(ftd.predict(X_test) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1e5bc-1929-49b2-819a-1d75c8bd9cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [1, 3, 5] #top k class accuracies to compute\n",
    "\n",
    "def eval(args):\n",
    "    \"\"\"\n",
    "    Run inference using model (and model2 if bottleneck)\n",
    "    Returns: (for notebook analysis)\n",
    "    all_class_labels: flattened list of class labels for each image\n",
    "    topk_class_outputs: array of top k class ids predicted for each image. Shape = size of test set * max(K)\n",
    "    all_class_outputs: array of all logit outputs for class prediction, shape = N_TEST * N_CLASS\n",
    "    all_attr_labels: flattened list of labels for each attribute for each image (length = N_ATTRIBUTES * N_TEST)\n",
    "    all_attr_outputs: flatted list of attribute logits (after ReLU/ Sigmoid respectively) predicted for each attribute for each image (length = N_ATTRIBUTES * N_TEST)\n",
    "    all_attr_outputs_sigmoid: flatted list of attribute logits predicted (after Sigmoid) for each attribute for each image (length = N_ATTRIBUTES * N_TEST)\n",
    "    wrong_idx: image ids where the model got the wrong class prediction (to compare with other models)\n",
    "    \"\"\"\n",
    "    if args.model_dir:\n",
    "        model = torch.load(args.model_dir)\n",
    "        \n",
    "    else:\n",
    "        model = None\n",
    "\n",
    "    if not hasattr(model, 'use_relu'):\n",
    "        if args.use_relu:\n",
    "            model.use_relu = True\n",
    "        else:\n",
    "            model.use_relu = False\n",
    "    if not hasattr(model, 'use_sigmoid'):\n",
    "        if args.use_sigmoid:\n",
    "            model.use_sigmoid = True\n",
    "        else:\n",
    "            model.use_sigmoid = False\n",
    "    if not hasattr(model, 'cy_fc'):\n",
    "        model.cy_fc = None\n",
    "    model = model.to(get_device())\n",
    "    model.eval()\n",
    "\n",
    "    if args.model_dir2:\n",
    "        if 'rf' in args.model_dir2:\n",
    "            model2 = joblib.load(args.model_dir2)\n",
    "        else:\n",
    "            model2 = torch.load(args.model_dir2)\n",
    "        if not hasattr(model2, 'use_relu'):\n",
    "            if args.use_relu:\n",
    "                model2.use_relu = True\n",
    "            else:\n",
    "                model2.use_relu = False\n",
    "        if not hasattr(model2, 'use_sigmoid'):\n",
    "            if args.use_sigmoid:\n",
    "                model2.use_sigmoid = True\n",
    "            else:\n",
    "                model2.use_sigmoid = False\n",
    "        model2 = model2.to(get_device())\n",
    "        model2.eval()\n",
    "    else:\n",
    "        model2 = None\n",
    "\n",
    "    if args.use_attr:\n",
    "        attr_acc_meter = [AverageMeter()]\n",
    "        if args.feature_group_results:  # compute acc for each feature individually in addition to the overall accuracy\n",
    "            for _ in range(args.n_attributes):\n",
    "                attr_acc_meter.append(AverageMeter())\n",
    "    else:\n",
    "        attr_acc_meter = None\n",
    "\n",
    "    class_acc_meter = []\n",
    "    for j in range(len(K)):\n",
    "        class_acc_meter.append(AverageMeter())\n",
    "    if args.eval_data == 'trainval':\n",
    "        train_dir = data_dir = os.path.join(BASE_DIR, args.data_dir, 'train.pkl')\n",
    "        val_dir = data_dir = os.path.join(BASE_DIR, args.data_dir, 'val.pkl')\n",
    "        loader = load_data([train_dir, val_dir], args.use_attr, args.no_img, args.batch_size, image_dir=args.image_dir,\n",
    "                           n_class_attr=args.n_class_attr)\n",
    "    else:\n",
    "        data_dir = os.path.join(BASE_DIR, args.data_dir, args.eval_data + '.pkl')\n",
    "        loader = load_data([data_dir], args.use_attr, args.no_img, args.batch_size, image_dir=args.image_dir,\n",
    "                           n_class_attr=args.n_class_attr)\n",
    "    all_outputs, all_targets = [], []\n",
    "    all_attr_labels, all_attr_outputs, all_attr_outputs_sigmoid, all_attr_outputs2 = [], [], [], []\n",
    "    all_class_labels, all_class_outputs, all_class_logits = [], [], []\n",
    "    topk_class_labels, topk_class_outputs = [], []\n",
    "\n",
    "    for data_idx, data in enumerate(loader):\n",
    "        if args.use_attr:\n",
    "            if args.no_img:  # A -> Y\n",
    "                inputs, labels = data\n",
    "                if isinstance(inputs, list):\n",
    "                    inputs = torch.stack(inputs).t().float()\n",
    "                inputs = inputs.float()\n",
    "                # inputs = torch.flatten(inputs, start_dim=1).float()\n",
    "            else:\n",
    "                inputs, labels, attr_labels = data\n",
    "                attr_labels = torch.stack(attr_labels).t()  # N x 312\n",
    "        else:  # simple finetune\n",
    "            inputs, labels = data\n",
    "\n",
    "        inputs_var = torch.autograd.Variable(inputs).to(get_device())\n",
    "        labels_var = torch.autograd.Variable(labels).to(get_device())\n",
    "        labels = labels.to(get_device()) if torch.cuda.is_available() else labels\n",
    "\n",
    "        if args.attribute_group:\n",
    "            outputs = []\n",
    "            f = open(args.attribute_group, 'r')\n",
    "            for line in f:\n",
    "                attr_model = torch.load(line.strip())\n",
    "                outputs.extend(attr_model(inputs_var))\n",
    "        else:\n",
    "            outputs = model(inputs_var)\n",
    "        if args.use_attr:\n",
    "            if args.no_img:  # A -> Y\n",
    "                class_outputs = outputs\n",
    "            else:\n",
    "                if args.bottleneck:\n",
    "                    if args.use_relu:\n",
    "                        attr_outputs = [torch.nn.ReLU()(o) for o in outputs]\n",
    "                        attr_outputs_sigmoid = [torch.nn.Sigmoid()(o) for o in outputs]\n",
    "                    elif args.use_sigmoid:\n",
    "                        attr_outputs = [torch.nn.Sigmoid()(o) for o in outputs]\n",
    "                        attr_outputs_sigmoid = attr_outputs\n",
    "                    else:\n",
    "                        attr_outputs = outputs\n",
    "                        attr_outputs_sigmoid = [torch.nn.Sigmoid()(o) for o in outputs]\n",
    "                    if model2:\n",
    "                        stage2_inputs = torch.cat(attr_outputs, dim=1)\n",
    "                        class_outputs = model2(stage2_inputs)\n",
    "                    else:  # for debugging bottleneck performance without running stage 2\n",
    "                        class_outputs = torch.zeros([inputs.size(0), N_CLASSES],\n",
    "                                                    dtype=torch.float64).to(get_device())  # ignore this\n",
    "                else:  # cotraining, end2end\n",
    "                    if args.use_relu:\n",
    "                        attr_outputs = [torch.nn.ReLU()(o) for o in outputs[1:]]\n",
    "                        attr_outputs_sigmoid = [torch.nn.Sigmoid()(o) for o in outputs[1:]]\n",
    "                    elif args.use_sigmoid:\n",
    "                        attr_outputs = [torch.nn.Sigmoid()(o) for o in outputs[1:]]\n",
    "                        attr_outputs_sigmoid = attr_outputs\n",
    "                    else:\n",
    "                        attr_outputs = outputs[1:]\n",
    "                        attr_outputs_sigmoid = [torch.nn.Sigmoid()(o) for o in outputs[1:]]\n",
    "\n",
    "                    class_outputs = outputs[0]\n",
    "\n",
    "                for i in range(args.n_attributes):\n",
    "                    acc = binary_accuracy(attr_outputs_sigmoid[i].squeeze(), attr_labels[:, i])\n",
    "                    acc = acc.data.cpu().numpy()\n",
    "                    # acc = accuracy(attr_outputs_sigmoid[i], attr_labels[:, i], topk=(1,))\n",
    "                    attr_acc_meter[0].update(acc, inputs.size(0))\n",
    "                    if args.feature_group_results:  # keep track of accuracy of individual attributes\n",
    "                        attr_acc_meter[i + 1].update(acc, inputs.size(0))\n",
    "\n",
    "                attr_outputs = torch.cat([o.unsqueeze(1) for o in attr_outputs], dim=1)\n",
    "                attr_outputs_sigmoid = torch.cat([o for o in attr_outputs_sigmoid], dim=1)\n",
    "                all_attr_outputs.extend(list(attr_outputs.flatten().data.cpu().numpy()))\n",
    "                all_attr_outputs_sigmoid.extend(list(attr_outputs_sigmoid.flatten().data.cpu().numpy()))\n",
    "                all_attr_labels.extend(list(attr_labels.flatten().data.cpu().numpy()))\n",
    "        else:\n",
    "            class_outputs = outputs[0]\n",
    "\n",
    "        _, topk_preds = class_outputs.topk(max(K), 1, True, True)\n",
    "        _, preds = class_outputs.topk(1, 1, True, True)\n",
    "        all_class_outputs.extend(list(preds.detach().cpu().numpy().flatten()))\n",
    "        all_class_labels.extend(list(labels.data.cpu().numpy()))\n",
    "        all_class_logits.extend(class_outputs.detach().cpu().numpy())\n",
    "        topk_class_outputs.extend(topk_preds.detach().cpu().numpy())\n",
    "        topk_class_labels.extend(labels.view(-1, 1).expand_as(preds))\n",
    "\n",
    "        np.set_printoptions(threshold=sys.maxsize)\n",
    "        class_acc = accuracy(class_outputs, labels, topk=K)  # only class prediction accuracy\n",
    "        for m in range(len(class_acc_meter)):\n",
    "            class_acc_meter[m].update(class_acc[m], inputs.size(0))\n",
    "\n",
    "    all_class_logits = np.vstack(all_class_logits)\n",
    "    topk_class_outputs = np.vstack([tco if isinstance(tco, np.ndarray) else tco.cpu() for tco in topk_class_outputs])\n",
    "    topk_class_labels = np.vstack([tcl if isinstance(tcl, np.ndarray) else tcl.cpu() for tcl in topk_class_labels])\n",
    "    wrong_idx = np.where(np.sum(topk_class_outputs == topk_class_labels, axis=1) == 0)[0]\n",
    "\n",
    "    for j in range(len(K)):\n",
    "        print('Average top %d class accuracy: %.5f' % (K[j], class_acc_meter[j].avg))\n",
    "\n",
    "    if args.use_attr and not args.no_img:  # print some metrics for attribute prediction performance\n",
    "        print('Average attribute accuracy: %.5f' % attr_acc_meter[0].avg)\n",
    "        all_attr_outputs_int = np.array(all_attr_outputs_sigmoid) >= 0.5\n",
    "        if args.feature_group_results:\n",
    "            n = len(all_attr_labels)\n",
    "            all_attr_acc, all_attr_f1 = [], []\n",
    "            for i in range(args.n_attributes):\n",
    "                acc_meter = attr_acc_meter[1 + i]\n",
    "                attr_acc = float(acc_meter.avg)\n",
    "                attr_preds = [all_attr_outputs_int[j] for j in range(n) if j % args.n_attributes == i]\n",
    "                attr_labels = [all_attr_labels[j] for j in range(n) if j % args.n_attributes == i]\n",
    "                attr_f1 = f1_score(attr_labels, attr_preds)\n",
    "                all_attr_acc.append(attr_acc)\n",
    "                all_attr_f1.append(attr_f1)\n",
    "\n",
    "            '''\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(20,10))\n",
    "            for plt_id, values in enumerate([all_attr_acc, all_attr_f1]):\n",
    "                axs[plt_id].set_xticks(np.arange(0, 1.1, 0.1))\n",
    "                if plt_id == 0:\n",
    "                    axs[plt_id].hist(np.array(values)/100.0, bins=np.arange(0, 1.1, 0.1), rwidth=0.8)\n",
    "                    axs[plt_id].set_title(\"Attribute accuracies distribution\")\n",
    "                else:\n",
    "                    axs[plt_id].hist(values, bins=np.arange(0, 1.1, 0.1), rwidth=0.8)\n",
    "                    axs[plt_id].set_title(\"Attribute F1 scores distribution\")\n",
    "            plt.savefig('/'.join(args.model_dir.split('/')[:-1]) + '.png')\n",
    "            '''\n",
    "            bins = np.arange(0, 1.01, 0.1)\n",
    "            acc_bin_ids = np.digitize(np.array(all_attr_acc) / 100.0, bins)\n",
    "            acc_counts_per_bin = [np.sum(acc_bin_ids == (i + 1)) for i in range(len(bins))]\n",
    "            f1_bin_ids = np.digitize(np.array(all_attr_f1), bins)\n",
    "            f1_counts_per_bin = [np.sum(f1_bin_ids == (i + 1)) for i in range(len(bins))]\n",
    "            print(\"Accuracy bins:\")\n",
    "            print(acc_counts_per_bin)\n",
    "            print(\"F1 bins:\")\n",
    "            print(f1_counts_per_bin)\n",
    "            np.savetxt(os.path.join(args.log_dir, 'concepts.txt'), f1_counts_per_bin)\n",
    "\n",
    "        balanced_acc, report = multiclass_metric(all_attr_outputs_int, all_attr_labels)\n",
    "        f1 = f1_score(all_attr_labels, all_attr_outputs_int)\n",
    "        print(\"Total 1's predicted:\", sum(np.array(all_attr_outputs_sigmoid) >= 0.5) / len(all_attr_outputs_sigmoid))\n",
    "        print('Avg attribute balanced acc: %.5f' % (balanced_acc))\n",
    "        print(\"Avg attribute F1 score: %.5f\" % f1)\n",
    "        print(report + '\\n')\n",
    "    return class_acc_meter, attr_acc_meter, all_class_labels, topk_class_outputs, all_class_logits, all_attr_labels, all_attr_outputs, all_attr_outputs_sigmoid, wrong_idx, all_attr_outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884a92a-a877-4bb7-9db0-10ddbde6c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_results, c_results = [], []\n",
    "for i, model_dir in enumerate(args.model_dirs):\n",
    "    args.model_dir = model_dir\n",
    "    args.model_dir2 = args.model_dirs2[i] if args.model_dirs2 else None\n",
    "    result = eval(args)\n",
    "    class_acc_meter, attr_acc_meter = result[0], result[1]\n",
    "    y_results.append(1 - class_acc_meter[0].avg[0].item() / 100.)\n",
    "    if attr_acc_meter is not None:\n",
    "        c_results.append(1 - attr_acc_meter[0].avg.item() / 100.)\n",
    "    else:\n",
    "        c_results.append(-1)\n",
    "values = (np.mean(y_results), np.std(y_results), np.mean(c_results), np.std(c_results))\n",
    "output_string = '%.4f %.4f %.4f %.4f' % values\n",
    "print_string = 'Error of y: %.4f +- %.4f, Error of C: %.4f +- %.4f' % values\n",
    "print(print_string)\n",
    "f = open(os.path.join(args.log_dir, 'results.txt'), \"a\")\n",
    "f.write(output_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ae1fe-ef4f-4be6-acf1-ddfb4d06e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(args.log_dir, 'results.txt'), \"a\")\n",
    "f.write(output_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc0664-571e-428d-834a-d69894e86a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2930d-b39e-4967-b3bb-3609fd0ebdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(args.log_dir, 'results.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17657b9b-c4e4-412e-8297-f372c6a3f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df44f78-10b2-4095-8f87-d5bcc2c295ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5ae35-45b9-4057-bf47-ee072a0db1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(args.log_dir, 'results.txt'), \"r\")\n",
    "content = file.read()\n",
    "print(content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea96cda-dbff-4a9f-a003-97047641256a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
